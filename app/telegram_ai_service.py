"""
Servi√ßo de IA Avan√ßado para Telegram Bot
Integra√ß√£o com CrewAI para an√°lises inteligentes e interativas
"""

import os
import logging
from typing import Dict, Any, Optional, List
from dotenv import load_dotenv
from openai import AsyncOpenAI

# IMPORTANTE: Carregar .env ANTES de usar os.getenv
# For√ßa carregar o .env do diret√≥rio raiz do projeto
from pathlib import Path
_env_path = Path(__file__).parent.parent / ".env"
load_dotenv(dotenv_path=_env_path, override=True)

# DEBUG: Imprimir chave carregada
_openai_key = os.getenv("OPENAI_API_KEY")
print(f"[telegram_ai_service.py] Carregando .env de: {_env_path}")
print(f"[telegram_ai_service.py] OPENAI_API_KEY carregada: ...{_openai_key[-10:] if _openai_key else 'NOT FOUND'}")

from app.database.models import (
    get_supabase_client,
    get_patient_full_profile,
    get_patient_by_cpf,
    create_patient,
    update_patient_history,
    save_case_analysis
)
from app.crews.cardio_crew import analyze_cardio_case
import uuid
from datetime import datetime

logger = logging.getLogger(__name__)

# Cliente OpenAI para an√°lises r√°pidas
_openai_key = os.getenv("OPENAI_API_KEY")
if not _openai_key:
    logger.error("OPENAI_API_KEY n√£o encontrada nas vari√°veis de ambiente!")
else:
    logger.info(f"üîë OpenAI Key carregada: ...{_openai_key[-10:]}")
openai_client = AsyncOpenAI(api_key=_openai_key)


class TelegramAIService:
    """Servi√ßo de IA para o bot do Telegram"""

    def __init__(self):
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    async def interpret_user_intent(self, text: str) -> Dict[str, Any]:
        """
        Interpreta a inten√ß√£o do usu√°rio usando IA

        Args:
            text: Texto do usu√°rio

        Returns:
            Dict com intent e par√¢metros extra√≠dos
        """
        try:
            prompt = f"""
Voc√™ √© um assistente m√©dico inteligente. Analise a mensagem do m√©dico e identifique a inten√ß√£o:

Mensagem: "{text}"

Classifique a inten√ß√£o em uma das seguintes categorias:
1. "create_prontuario" - M√©dico quer criar/registrar um prontu√°rio
2. "search_patient" - M√©dico quer buscar informa√ß√µes de um paciente
3. "clinical_question" - M√©dico tem uma pergunta cl√≠nica/cient√≠fica
4. "update_history" - M√©dico quer atualizar hist√≥rico de paciente
5. "general_analysis" - An√°lise geral de caso cl√≠nico

Se for busca de paciente, tente extrair:
- CPF (se mencionado)
- Nome do paciente (se mencionado)

Se for prontu√°rio ou an√°lise, identifique:
- Se h√° dados cl√≠nicos suficientes
- Se precisa de mais informa√ß√µes

Responda em JSON puro (sem markdown):
{{
  "intent": "categoria",
  "confidence": 0.0-1.0,
  "extracted_data": {{
    "cpf": "opcional",
    "patient_name": "opcional",
    "has_clinical_data": true/false
  }},
  "needs_more_info": true/false,
  "suggested_question": "pergunta para coletar mais dados se necess√°rio"
}}
"""

            response = await openai_client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )

            import json
            result_text = response.choices[0].message.content.strip()

            # Remove markdown se existir
            if result_text.startswith("```"):
                result_text = result_text.split("```")[1]
                if result_text.startswith("json"):
                    result_text = result_text[4:]

            result = json.loads(result_text)

            return result

        except Exception as e:
            logger.error(f"Erro ao interpretar inten√ß√£o: {e}")
            return {
                "intent": "general_analysis",
                "confidence": 0.5,
                "extracted_data": {},
                "needs_more_info": False
            }

    async def search_patient_by_query(self, query: str) -> Optional[Dict[str, Any]]:
        """
        Busca paciente por CPF ou nome usando IA para extrair informa√ß√£o

        Args:
            query: Query de busca (ex: "buscar paciente Jo√£o Silva", "CPF 123.456.789-00")

        Returns:
            Dados do paciente se encontrado
        """
        try:
            # Extrai CPF se houver
            import re
            cpf_match = re.search(r'\d{3}\.?\d{3}\.?\d{3}-?\d{2}', query)

            if cpf_match:
                cpf = cpf_match.group(0)
                patient = await get_patient_by_cpf(cpf)
                if patient:
                    return patient

            # Se n√£o encontrou por CPF, busca por nome no Supabase
            supabase = get_supabase_client()

            # Extrai poss√≠vel nome do paciente
            words = query.lower().replace("paciente", "").replace("buscar", "").strip()

            response = supabase.table("patients")\
                .select("*")\
                .ilike("full_name", f"%{words}%")\
                .limit(1)\
                .execute()

            if response.data:
                return response.data[0]

            return None

        except Exception as e:
            logger.error(f"Erro ao buscar paciente: {e}")
            return None

    async def get_patient_summary(self, patient_id: str) -> str:
        """
        Gera resumo inteligente do paciente usando IA

        Args:
            patient_id: ID do paciente

        Returns:
            Resumo formatado do paciente
        """
        try:
            profile = await get_patient_full_profile(patient_id)

            if profile["status"] == "error":
                return "‚ùå Paciente n√£o encontrado"

            patient = profile["patient"]
            history = profile.get("history", {})
            recent_cases = profile.get("recent_cases", [])

            # Monta contexto para IA
            context = f"""
DADOS DO PACIENTE:
- Nome: {patient['full_name']}
- Idade: {patient.get('age', 'N/A')} anos
- Sexo: {patient.get('gender', 'N/A')}
- Tipo sangu√≠neo: {patient.get('blood_type', 'N/A')}

HIST√ìRICO:
- Comorbidades: {history.get('comorbidities', [])}
- Alergias: {history.get('allergies', [])}
- Medica√ß√µes atuais: {history.get('current_medications', [])}
- Fatores de risco card√≠aco: {history.get('cardiac_risk_factors', [])}

CONSULTAS RECENTES: {len(recent_cases)} consultas registradas
"""

            # Gera resumo com IA
            prompt = f"""
Voc√™ √© um assistente m√©dico. Gere um resumo cl√≠nico conciso e profissional do paciente:

{context}

Formato do resumo:
üìã RESUMO DO PACIENTE

**Identifica√ß√£o:** [nome, idade, sexo]
**Perfil de Risco:** [avalia√ß√£o breve dos fatores de risco]
**Hist√≥rico Relevante:** [comorbidades e alergias principais]
**Acompanhamento:** [quantas consultas, √∫ltima consulta se houver]

Seja objetivo e cl√≠nico.
"""

            response = await openai_client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5
            )

            summary = response.choices[0].message.content.strip()

            return summary

        except Exception as e:
            logger.error(f"Erro ao gerar resumo: {e}")
            return f"‚ùå Erro ao gerar resumo: {str(e)}"

    async def create_prontuario_from_voice(
        self,
        transcription: str,
        doctor_name: str,
        doctor_crm: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Cria prontu√°rio a partir de transcri√ß√£o de voz
        Extrai dados do paciente e cria an√°lise completa

        Args:
            transcription: Texto transcrito
            doctor_name: Nome do m√©dico
            doctor_crm: CRM do m√©dico

        Returns:
            Resultado da cria√ß√£o do prontu√°rio
        """
        try:
            # Usa IA para extrair dados estruturados
            extraction_prompt = f"""
Voc√™ √© um assistente m√©dico. Extraia os seguintes dados da transcri√ß√£o da consulta:

Transcri√ß√£o: "{transcription}"

Identifique e extraia (se mencionado):
1. Nome do paciente
2. Idade
3. Sexo
4. Queixa principal
5. Hist√≥ria da doen√ßa atual
6. Comorbidades
7. Medica√ß√µes em uso
8. Sinais vitais (PA, FC, etc.)

Responda em JSON puro:
{{
  "patient_name": "nome ou null",
  "age": n√∫mero ou null,
  "gender": "M/F/Outro ou null",
  "chief_complaint": "texto",
  "clinical_data_complete": true/false
}}
"""

            extraction_response = await openai_client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": extraction_prompt}],
                temperature=0.2
            )

            import json
            import re
            extracted_text = extraction_response.choices[0].message.content.strip()

            # Remove markdown de forma robusta
            # Padr√£o: ```json\n{...}\n``` ou ```{...}``` ou apenas {...}
            extracted_text = re.sub(r'^```(?:json)?\s*', '', extracted_text)
            extracted_text = re.sub(r'\s*```$', '', extracted_text)
            extracted_text = extracted_text.strip()

            extracted = json.loads(extracted_text)

            # Gera an√°lise com CrewAI
            case_id = str(uuid.uuid4())
            analysis_result = await analyze_cardio_case(
                transcription=transcription,
                doctor_name=doctor_name,
                case_id=case_id
            )

            if analysis_result["status"] == "error":
                return analysis_result

            # Salva no banco (se tiver dados do paciente, pode vincular)
            # Por enquanto salva sem vincular a paciente
            await save_case_analysis(
                case_id=case_id,
                doctor_name=doctor_name,
                transcription=transcription,
                analysis_result=analysis_result["analysis"],
                doctor_crm=doctor_crm,
                patient_id=None  # TODO: Criar ou vincular paciente
            )

            return {
                "status": "success",
                "case_id": case_id,
                "analysis": analysis_result["analysis"],
                "extracted_patient_data": extracted,
                "message": "‚úÖ Prontu√°rio criado com sucesso!"
            }

        except Exception as e:
            logger.error(f"Erro ao criar prontu√°rio: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    async def get_clinical_suggestion(
        self,
        patient_history: str,
        current_symptoms: str
    ) -> str:
        """
        Gera sugest√µes cl√≠nicas baseadas em hist√≥rico e sintomas

        Args:
            patient_history: Hist√≥rico do paciente
            current_symptoms: Sintomas atuais

        Returns:
            Sugest√µes cl√≠nicas formatadas
        """
        try:
            prompt = f"""
Voc√™ √© um cardiologista experiente. Com base no hist√≥rico e sintomas atuais, forne√ßa sugest√µes cl√≠nicas:

HIST√ìRICO DO PACIENTE:
{patient_history}

SINTOMAS ATUAIS:
{current_symptoms}

Forne√ßa:
1. Hip√≥teses diagn√≥sticas principais (top 3)
2. Exames complementares sugeridos
3. Condutas iniciais recomendadas
4. Sinais de alerta (red flags)

Formato: Use emojis para organizar, seja objetivo e baseado em guidelines.
"""

            response = await openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um cardiologista especialista. Forne√ßa sugest√µes baseadas em evid√™ncias e guidelines."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4
            )

            suggestions = response.choices[0].message.content.strip()

            return f"""
üí° SUGEST√ïES CL√çNICAS

{suggestions}

‚ö†Ô∏è IMPORTANTE: Estas s√£o sugest√µes de apoio √† decis√£o.
A avalia√ß√£o cl√≠nica e conduta final s√£o do m√©dico assistente.
"""

        except Exception as e:
            logger.error(f"Erro ao gerar sugest√µes: {e}")
            return f"‚ùå Erro ao gerar sugest√µes: {str(e)}"

    async def chat_with_doctor(self, message: str, is_logged_in: bool = False, doctor_name: str = None) -> Dict[str, Any]:
        """
        Conversa√ß√£o inteligente com o m√©dico

        Args:
            message: Mensagem do m√©dico
            is_logged_in: Se o m√©dico est√° logado
            doctor_name: Nome do m√©dico

        Returns:
            Dict com 'response' (texto da resposta) e 'action' (sugest√£o de a√ß√£o)
        """
        try:
            if is_logged_in:
                system_prompt = f"""
Voc√™ √© a IA assistente do ClinicaPro Cardio, conversando com {doctor_name or 'um m√©dico'}.

O m√©dico j√° est√° logado no sistema. Voc√™ deve:
- Ser amig√°vel, profissional e prestativo
- Se for uma sauda√ß√£o casual (oi, ol√°, tudo bem), responda de forma amig√°vel e explique as funcionalidades
- Se for dados cl√≠nicos curtos, pe√ßa mais detalhes educadamente
- Explique que ele pode:
  * Enviar √°udio descrevendo a consulta ‚Üí voc√™ transcreve e cria prontu√°rio automaticamente
  * Enviar dados do paciente (sintomas, hist√≥rico) ‚Üí voc√™ gera an√°lise cardiol√≥gica completa
  * Usar /prontuario para modo interativo guiado
  * Enviar fotos de ECG/exames para an√°lise integrada

Seja breve (m√°ximo 4 linhas) mas informativo.
"""
            else:
                system_prompt = """
Voc√™ √© a IA assistente do ClinicaPro Cardio.

O m√©dico N√ÉO est√° logado ainda. Voc√™ deve:
- Ser amig√°vel, profissional e conversacional
- Se ele diz "j√° tenho conta", diga: "√ìtimo! Use /start e clique em üîê Fazer Login para acessar o sistema."
- Se pergunta algo sobre funcionalidades, responda normalmente e ao final mencione que precisa fazer login
- Se for sauda√ß√£o casual, seja amig√°vel e mencione brevemente as funcionalidades
- IMPORTANTE: N√£o fique repetindo a mesma mensagem. Varie as respostas e seja natural.

Seja breve (m√°ximo 3 linhas).
"""

            response = await openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                temperature=0.7,
                max_tokens=200
            )

            ai_response = response.choices[0].message.content.strip()

            # Determina a√ß√£o sugerida
            action = None
            if not is_logged_in:
                action = "login_required"
            elif len(message) < 30 and any(word in message.lower() for word in ['oi', 'ol√°', 'bom dia', 'boa tarde', 'boa noite', 'tudo bem']):
                action = "greeting"
            else:
                action = "continue"

            return {
                "response": ai_response,
                "action": action
            }

        except Exception as e:
            logger.error(f"Erro na conversa√ß√£o: {e}")
            return {
                "response": "Desculpe, tive um problema. Tente novamente ou use /help para ver os comandos dispon√≠veis.",
                "action": "error"
            }


# Inst√¢ncia global
telegram_ai_service = TelegramAIService()
